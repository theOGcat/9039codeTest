{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as gb\n",
    "import os\n",
    "import keras_tuner as KT\n",
    "import seaborn as sns\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from sklearn.utils import resample\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import copy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "# Enable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('archive/train.csv',sep=\" \",header=None)\n",
    "train_df.columns=['patient id', 'filename', 'label','data source']\n",
    "train_df=train_df.drop(['patient id', 'data source'], axis=1 )\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('archive/test.csv',sep=\" \",header=None)\n",
    "test_df.columns=['patient id', 'filename', 'label','data source']\n",
    "test_df=test_df.drop(['patient id', 'data source'], axis=1 )\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p_count = train_df['label'].value_counts()['positive']\n",
    "train_n_count = train_df['label'].value_counts()['negative']\n",
    "\n",
    "print(train_df['label'].value_counts())\n",
    "print(test_df['label'].value_counts())\n",
    "train_df = shuffle(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder_path = 'archive/train'\n",
    "test_folder_path = 'archive/test'\n",
    "\n",
    "#Print out each folder's info\n",
    "\n",
    "def count_photos(folder_path):\n",
    "    count = 0\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "            count +=1\n",
    "    return count\n",
    "\n",
    "\n",
    "def count_photos_in_folders(train_folder_path, test_folder_path):\n",
    "    train_count = count_photos(train_folder_path)\n",
    "    test_count = count_photos(test_folder_path)\n",
    "    return (train_count, test_count)\n",
    "\n",
    "# 将数据信息打印出来\n",
    "# 2. Print out info for each dataset\n",
    "train_count, test_count = count_photos_in_folders(train_folder_path, test_folder_path)\n",
    "\n",
    "print(f\"Train folder contains {train_count} photos.\")\n",
    "print(f\"Test folder contains {test_count} photos.\")\n",
    "\n",
    "train_data_size = [train_p_count, train_n_count]\n",
    "labels = ['positive', 'negative']\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12, 8))\n",
    "sns.barplot(x=train_data_size, y=labels, ax=axs)\n",
    "axs.set_title('Training data categories')\n",
    "axs.set(xlabel='Image number')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative  = train_df[train_df['label']=='negative']   #negative values in class column\n",
    "positive = train_df[train_df['label']=='positive']  #positive values in class column\n",
    "\n",
    "df_majority_downsampled_neg = resample(negative, replace = True, n_samples = 5000)\n",
    "df_majority_downsampled_pos = resample(positive, replace = True, n_samples = 5000)\n",
    "\n",
    "train_df = pd.concat([df_majority_downsampled_pos, df_majority_downsampled_neg])\n",
    "train_df = shuffle(train_df) # shuffling so that there is particular sequence\n",
    "\n",
    "train_df, valid_df = train_test_split(train_df, train_size=0.8, random_state=0)\n",
    "\n",
    "print(f\"Negative and positive values of train:\\n {train_df['label'].value_counts()}\")\n",
    "print(f\"Negative and positive values of validation:\\n {valid_df['label'].value_counts()}\")\n",
    "print(f\"Negative and positive values of test:\\n {test_df['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据，把train分成train set和validation set，将batch size设置为64\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "#Now fit the them to get the images from directory (name of the images are given in dataframe) with augmentation\n",
    "\n",
    "\n",
    "train_gen = train_datagen.flow_from_dataframe(dataframe = train_df, directory='archive/train', x_col='filename', \n",
    "                                              y_col='label', target_size=(256,256), batch_size=64, \n",
    "                                               class_mode='binary')\n",
    "val_gen = test_datagen.flow_from_dataframe(dataframe = valid_df, directory='archive/train', x_col='filename',\n",
    "                                             y_col='label', target_size=(256,256), batch_size=64, \n",
    "                                            class_mode='binary')\n",
    "test_gen = test_datagen.flow_from_dataframe(dataframe = test_df, directory='archive/test', x_col='filename', \n",
    "                                            y_col='label', target_size=(256,256), batch_size=64,\n",
    "                                             class_mode='binary')\n",
    "labels = {value: key for key, value in train_gen.class_indices.items()}\n",
    "#class mode binary because we want the classifier to predict covid or not\n",
    "#target size (200,200) means we want the images to resized to 200*200\n",
    "\n",
    "#Examine the first image in the training dataset and print the label which corresponding to it.\n",
    "print(labels)\n",
    "images, labels = next(train_gen)\n",
    "# Get the filenames associated with the images in the batch\n",
    "filenames = train_gen.filenames\n",
    "# Print the filename and label for the first image in the batch\n",
    "print(filenames[0], labels[0])\n",
    "# Plot the first image in the batch\n",
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "# Load your fine-tuned CNN model\n",
    "cnn_model = keras.models.load_model('Best_CNN_only')\n",
    "\n",
    "# Remove the last layer to use the model as a feature extractor\n",
    "feature_extractor = Model(inputs=cnn_model.input, outputs=cnn_model.layers[-2].output)\n",
    "train_features = feature_extractor.predict(train_gen)\n",
    "val_features = feature_extractor.predict(val_gen)\n",
    "test_features = feature_extractor.predict(test_gen)\n",
    "\n",
    "\n",
    "train_labels = np.concatenate([train_gen[i][1] for i in range(len(train_gen))])\n",
    "val_labels = np.concatenate([val_gen[i][1] for i in range(len(val_gen))])\n",
    "test_labels = np.concatenate([test_gen[i][1] for i in range(len(test_gen))])\n",
    "\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(max_depth=2)\n",
    "adaboost = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=20)\n",
    "\n",
    "adaboost.fit(train_features, train_labels)\n",
    "val_preds = adaboost.predict(val_features)\n",
    "val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "print(f\"Validation accuracy: {val_accuracy}\")\n",
    "\n",
    "test_preds = adaboost.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
